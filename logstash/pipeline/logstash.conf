############# INPUT ######################

input {
	beats {
		port => 5000
		# port => 5063
		# tags => ["test", "geoserver"]
		# ssl => true
		# ssl_certificate => "/etc/pki/tls/certs/logstash-forwarder.crt"
		# ssl_key => "/etc/pki/tls/private/logstash-forwarder.key"
		# ssl_verify_mode => "none"
	}
 stdin{}
}
################## FILTER ######################


### Add some custom fields and tags

filter {
  mutate {
    add_field => { "client_name" => "ComuneBolzano"  }
  }

### Parse GeoServer audit files

 if "geoserver-audit" in [type] {
    grok {
	patterns_dir => ["/usr/share/logstash/patterns.d/"]
        match => { "message" => "%{INT:RequestId},%{IPORHOST:ServerHost},(%{WORD:Service})?,((?<ServiceVersion>[\d\.]+))?,(%{WORD:Operation})?,(%{WORD:SubOperation})?,\"((?<Layers>[-\w\s:,]+))?\",(\"%{BASE10NUM:BBox1:float},%{BASE10NUM:BBox2:float},%{BASE10NUM:BBox3:float},%{BASE10NUM:BBox4:float}\")?,\"(%{URIPATH:RequestPath})?\",\"((?<QueryString>[-?A-Za-z0-9&='<> ().,;:_/+#]+))?\",\"(%{WORD:RequestBody})?\",%{WORD:RequestMethod},\"%{TIMESTAMP_ISO8601:StartTime}\",\"%{TIMESTAMP_ISO8601:EndTime}\",(%{NUMBER:ResponseTime:int})?,\"%{IPORHOST:ClientAddress}(:)?(%{NUMBER:ClientPort})?\",%{QS:remoteUser},%{QS:UserAgent},%{NUMBER:ResponseHTTPStatus:int},%{NUMBER:ResponseLength:int},%{QS:ResponseContentType},\"(%{WORD:geowebcache-cache-result})?\",(%{QS:geowebcache-cache-miss-reason})?,\"(%{WORD:Error})?\",(%{QS:ErrorMessage})?"
        }
	add_tag => [ "grokked"]
    }
    kv {
        source => "QueryString"
        field_split => "&"
	transform_key => "uppercase"
    }
    # Fix some fileds before sending over to Elasticsearch
    mutate {
      lowercase => [ "TILED", "Error"]
      uppercase => [ "Service", "SERVICE"]
      convert => { "RequestId" => "integer"}
      convert => { "WIDTH" => "integer"}
      convert => { "HEIGHT" => "integer"}
      convert => { "Error" => "boolean"}
      add_tag => [ "geoserver", "audit", "geoserver-audit" ]
    }
    if ![TILED] {
      mutate { add_field => { "TILED" => "false" } }
    } 
    mutate {
      convert => { "TILED" => "boolean"}
    }
    date {
      match => ["StartTime", "ISO8601"]
      target => "@timestamp"
      add_tag => ["dated"]
    }
    geoip {
      source => "ClientAddress"
        target => "geoip"
#        database => "/etc/logstash/GeoLiteCity.dat"
        add_field => [ "[geoip][coordinates]", "%{[geoip][longitude]}" ]
        add_field => [ "[geoip][coordinates]", "%{[geoip][latitude]}"  ]
    }
  }
  else if "geoserver-logs" in [type] {
    mutate {
      add_tag => [ "geoserver", "log", "geoserver-logs", "geoserver-log"]
    }
#    # moved to Filebeat side
#    multiline {
#      pattern => "^%{YEAR}-%{MONTHNUM}-%{MONTHDAY} %{HOUR}:%{MINUTE}:%{SECOND},%{POSINT}?"
#      negate => true
#      what => previous
#    }

    grok {
      patterns_dir => [ "/usr/share/logstash/patterns.d/" ]
      match => {
       "message" =>[ "%{GSLOG}" ]
      }
      add_tag => ["grokked"]
    }
    if "DEBUG" in [logLevel] or "TRACE" in [logLevel] or "INFO" in [logLevel] {
      drop { }
    }
#    date {
#      pattern => [ "timestamp", "^%{YEAR}-%{MONTHNUM}-%{MONTHDAY} %{HOUR}:%{MINUTE}:%{SECOND},%{POSINT}?" ]
#    }
#      add_tag => ["dated"]
  }
}


##################### OUTPUT #############################

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logstash-maps-prod-%{+YYYY.MM.dd}"
    user => "elastic"
    password => "CHANGEME"
}

stdout { codec => rubydebug }
}

